{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS289A Project F NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(246810)\n",
    "np.random.seed(246810)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5  # a small number\n",
    "# Vectorized function for hashing for np efficiency\n",
    "def w(x):\n",
    "    return np.int(hash(x)) % 1000\n",
    "\n",
    "h = np.vectorize(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some scripts to merge the SW time and HW time + features CSV files\n",
    "# no need to run again !!\n",
    "\n",
    "# path_chstone= '../data/baseline_chstone.csv'\n",
    "# chstone = pd.read_csv(path_chstone, delimiter=',')\n",
    "\n",
    "# path_random = '../data/baseline_random.csv'\n",
    "# random = pd.read_csv(path_random, delimiter=',')\n",
    "# random.sort_values(by = ['program'])\n",
    "\n",
    "# random_sw=pd.read_csv('../data/sw_perf_random.csv', delimiter=',')\n",
    "# chstone_sw=pd.read_csv('../data/sw_perf_chstone.csv', delimiter=',')\n",
    "\n",
    "# merged_random = random.merge(random_sw, left_on='program', right_on='program')\n",
    "# merged_chstone = chstone.merge(chstone_sw, left_on='program', right_on='program')\n",
    "\n",
    "# merged_random.to_csv('../data/final_random.csv', index=False)\n",
    "# merged_chstone.to_csv('../data/final_chstone.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"csmith_random_programs\"\n",
    "data = pd.read_csv('final_random.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a). Pre-process the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011, 116)\n",
      "(3862, 116)\n",
      "(12873, 116)\n",
      "[2915.27039334195 3064.5126890095776 3127.9902745113 ...\n",
      " 2596.5991783791956 2804.3891404735623 3077.551395099053]\n"
     ]
    }
   ],
   "source": [
    "# set out training set to be 70% of total; 30% \n",
    "# random_idx = random.randint(0, np.shape(data)[0]) #27\n",
    "num_train = round(np.shape(data)[0]*0.7)\n",
    "train_data = data.values[0:num_train,:]\n",
    "test_data =  data.values[num_train:, :]\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(data))\n",
    "\n",
    "train_speedup = (train_data[:, -1] / train_data[:, 2]) # \n",
    "test_speedup = (test_data[:, -1] / test_data[:, 2]) # -O3\n",
    "print(train_speedup)\n",
    "# log_train_speedup = np.log10(train_speedup.astype(float))\n",
    "# log_test_speedup = np.log10(test_speedup.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA of speed up from training set\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.style.use('ggplot')\n",
    "plt.hist(train_speedup, bins=100, range =(0, 7000))\n",
    "plt.hist(test_speedup, bins=100, range = (0, 7000))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5433359227610698\n",
      "0.5468669083376488\n"
     ]
    }
   ],
   "source": [
    "# Get binary preduction output: is speedup (HW vs SW) > 2800 \n",
    "y = (train_speedup > 2800).astype(int)\n",
    "X = train_data[:,-57:-1]\n",
    "y_test = (test_speedup > 2800).astype(int)\n",
    "X_test = test_data[:,-57:-1]\n",
    "print(np.count_nonzero(y) / len(y))\n",
    "print(np.count_nonzero(y_test) / len(y_test))\n",
    "assert(len(y) == np.shape(train_data)[0])\n",
    "assert(len(y_test) == np.shape(test_data)[0] )\n",
    "\n",
    "features = data.columns.values[-57:-1]\n",
    "assert len(features) == 56\n",
    "class_names = [\"On-Chip\", \"Not On-Chip\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class trainData(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.length = self.x.shape[0]\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class testData(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "trainset = trainData(X_train,y)\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "validation_data = testData(torch.FloatTensor(X_val))\n",
    "\n",
    "train_loader = DataLoader(trainset,batch_size=64,shuffle=False)\n",
    "test_loader = DataLoader(test_data,batch_size=1,shuffle=False)\n",
    "validation_loader = DataLoader(validation_data,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_shape,width = 64, depth = 3, activation = torch.relu):\n",
    "        super(Net,self).__init__()\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.activation = activation\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.append(nn.Linear(input_shape,self.width))\n",
    "        for _ in range(1,self.depth-1):\n",
    "            self.layers.append(nn.Linear(width,self.width))\n",
    "        self.layers.append(nn.Linear(self.width,1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for i in range(0,self.depth-1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr_ = 0.001\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    \"\"\"Helper function for getting the accuracy of a batch.\"\"\"\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc\n",
    "\n",
    "def train_model(model):\n",
    "    \"\"\"Train a model with the specified dimensions and activation fn.\"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=lr_)\n",
    "    # Combines sigmoid and BCE in one class\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    model.train()\n",
    "    for e in range(1, epochs+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss/len(train_loader), epoch_acc/len(train_loader)\n",
    "        \n",
    "def evaluate_model(model, test_loader, y_test):\n",
    "    \"\"\"Return the accuracy on a test or validation set\"\"\"\n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    return np.mean(y_pred_list == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 16| Depth: 2 | Activation: ReLU | Train Accuracy: 77.28368794326241 | Validation Accuracy: 0.7591921284308648\n",
      "Width: 16| Depth: 2 | Activation: tanh | Train Accuracy: 77.09219858156028 | Validation Accuracy: 0.7591921284308648\n",
      "Width: 16| Depth: 3 | Activation: ReLU | Train Accuracy: 77.0354609929078 | Validation Accuracy: 0.7607457276022787\n",
      "Width: 16| Depth: 3 | Activation: tanh | Train Accuracy: 76.95744680851064 | Validation Accuracy: 0.7622993267736924\n",
      "Width: 16| Depth: 4 | Activation: ReLU | Train Accuracy: 77.14893617021276 | Validation Accuracy: 0.7586742620403936\n",
      "Width: 16| Depth: 4 | Activation: tanh | Train Accuracy: 77.09219858156028 | Validation Accuracy: 0.7622993267736924\n",
      "Width: 32| Depth: 2 | Activation: ReLU | Train Accuracy: 77.38297872340425 | Validation Accuracy: 0.7659243915069912\n",
      "Width: 32| Depth: 2 | Activation: tanh | Train Accuracy: 76.8936170212766 | Validation Accuracy: 0.7602278612118073\n",
      "Width: 32| Depth: 3 | Activation: ReLU | Train Accuracy: 77.25531914893617 | Validation Accuracy: 0.7628171931641636\n",
      "Width: 32| Depth: 3 | Activation: tanh | Train Accuracy: 77.17021276595744 | Validation Accuracy: 0.7638529259451061\n",
      "Width: 32| Depth: 4 | Activation: ReLU | Train Accuracy: 77.34751773049645 | Validation Accuracy: 0.7591921284308648\n",
      "Width: 32| Depth: 4 | Activation: tanh | Train Accuracy: 77.09219858156028 | Validation Accuracy: 0.7612635939927499\n",
      "Width: 64| Depth: 2 | Activation: ReLU | Train Accuracy: 77.28368794326241 | Validation Accuracy: 0.7633350595546349\n",
      "Width: 64| Depth: 2 | Activation: tanh | Train Accuracy: 77.02836879432624 | Validation Accuracy: 0.7602278612118073\n",
      "Width: 64| Depth: 3 | Activation: ReLU | Train Accuracy: 77.35460992907801 | Validation Accuracy: 0.7648886587260487\n",
      "Width: 64| Depth: 3 | Activation: tanh | Train Accuracy: 77.07801418439716 | Validation Accuracy: 0.7607457276022787\n",
      "Width: 64| Depth: 4 | Activation: ReLU | Train Accuracy: 77.25531914893617 | Validation Accuracy: 0.76540652511652\n",
      "Width: 64| Depth: 4 | Activation: tanh | Train Accuracy: 77.12765957446808 | Validation Accuracy: 0.7602278612118073\n"
     ]
    }
   ],
   "source": [
    "widths = [16, 32, 64]\n",
    "depths = [2, 3, 4]\n",
    "activations = {torch.relu : 'ReLU', torch.tanh : 'tanh'}\n",
    "for width in widths:\n",
    "    for depth in depths:\n",
    "        for activation in activations.keys():\n",
    "            # Model , Optimizer, Loss\n",
    "            model = Net(input_shape=X_train.shape[1],width = width, depth = depth, activation = activation)\n",
    "            model.to(device)\n",
    "            train_loss, train_acc = train_model(model)\n",
    "            validation_acc = evaluate_model(model, validation_loader, y_val)\n",
    "            print(f'Width: {width}| Depth: {depth} | Activation: {activations[activation]} | Train Accuracy: {train_acc} | Validation Accuracy: {validation_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the validation set for training final model\n",
    "X_train = np.concatenate((X_train, X_val))\n",
    "y_train = np.concatenate((y, y_val))\n",
    "trainset = trainData(X_train,y_train)\n",
    "train_loader = DataLoader(trainset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5109115235986765, 77.45029239766082)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train best model\n",
    "width = 32\n",
    "depth = 2\n",
    "activation = torch.relu\n",
    "model = Net(input_shape=X_train.shape[1],width = width, depth = depth, activation = activation)\n",
    "model.to(device)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71       881\n",
      "           1       0.74      0.87      0.80      1050\n",
      "\n",
      "    accuracy                           0.76      1931\n",
      "   macro avg       0.77      0.75      0.76      1931\n",
      "weighted avg       0.77      0.76      0.76      1931\n",
      "\n",
      "Accuracy:\n",
      "0.7638529259451061\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))\n",
    "print(\"Accuracy:\")\n",
    "print(np.mean(y_pred_list == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
