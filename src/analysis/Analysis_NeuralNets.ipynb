{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS289A Project F NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(246810)\n",
    "np.random.seed(246810)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5  # a small number\n",
    "# Vectorized function for hashing for np efficiency\n",
    "def w(x):\n",
    "    return np.int(hash(x)) % 1000\n",
    "\n",
    "h = np.vectorize(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some scripts to merge the SW time and HW time + features CSV files\n",
    "# no need to run again !!\n",
    "\n",
    "# path_chstone= '../data/baseline_chstone.csv'\n",
    "# chstone = pd.read_csv(path_chstone, delimiter=',')\n",
    "\n",
    "# path_random = '../data/baseline_random.csv'\n",
    "# random = pd.read_csv(path_random, delimiter=',')\n",
    "# random.sort_values(by = ['program'])\n",
    "\n",
    "# random_sw=pd.read_csv('../data/sw_perf_random.csv', delimiter=',')\n",
    "# chstone_sw=pd.read_csv('../data/sw_perf_chstone.csv', delimiter=',')\n",
    "\n",
    "# merged_random = random.merge(random_sw, left_on='program', right_on='program')\n",
    "# merged_chstone = chstone.merge(chstone_sw, left_on='program', right_on='program')\n",
    "\n",
    "# merged_random.to_csv('../data/final_random.csv', index=False)\n",
    "# merged_chstone.to_csv('../data/final_chstone.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"csmith_random_programs\"\n",
    "data = pd.read_csv('../data/final_random.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a). Pre-process the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011, 116)\n",
      "(3862, 116)\n",
      "(12873, 116)\n",
      "[2915.27039334195 3064.5126890095776 3127.9902745113 ...\n",
      " 2596.5991783791956 2804.3891404735623 3077.551395099053]\n"
     ]
    }
   ],
   "source": [
    "# set out training set to be 70% of total; 30% \n",
    "# random_idx = random.randint(0, np.shape(data)[0]) #27\n",
    "num_train = round(np.shape(data)[0]*0.7)\n",
    "train_data = data.values[0:num_train,:]\n",
    "test_data =  data.values[num_train:, :]\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(data))\n",
    "\n",
    "train_speedup = (train_data[:, -1] / train_data[:, 2]) # \n",
    "test_speedup = (test_data[:, -1] / test_data[:, 2]) # -O3\n",
    "print(train_speedup)\n",
    "# log_train_speedup = np.log10(train_speedup.astype(float))\n",
    "# log_test_speedup = np.log10(test_speedup.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA of speed up from training set\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.style.use('ggplot')\n",
    "plt.hist(train_speedup, bins=100, range =(0, 7000))\n",
    "plt.hist(test_speedup, bins=100, range = (0, 7000))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5433359227610698\n",
      "0.5468669083376488\n"
     ]
    }
   ],
   "source": [
    "# Get binary preduction output: is speedup (HW vs SW) > 2800 \n",
    "y = (train_speedup > 2800).astype(int)\n",
    "X = train_data[:,-57:-1]\n",
    "y_test = (test_speedup > 2800).astype(int)\n",
    "X_test = test_data[:,-57:-1]\n",
    "print(np.count_nonzero(y) / len(y))\n",
    "print(np.count_nonzero(y_test) / len(y_test))\n",
    "assert(len(y) == np.shape(train_data)[0])\n",
    "assert(len(y_test) == np.shape(test_data)[0] )\n",
    "\n",
    "features = data.columns.values[-57:-1]\n",
    "assert len(features) == 56\n",
    "class_names = [\"On-Chip\", \"Not On-Chip\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class trainData(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.length = self.x.shape[0]\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "class testData(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "    \n",
    "trainset = trainData(X_train,y)\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "validation_data = testData(torch.FloatTensor(X_val))\n",
    "\n",
    "train_loader = DataLoader(trainset,batch_size=64,shuffle=False)\n",
    "test_loader = DataLoader(test_data,batch_size=1,shuffle=False)\n",
    "validation_loader = DataLoader(validation_data,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_shape,width = 64, depth = 3, activation = torch.relu):\n",
    "        super(Net,self).__init__()\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.activation = activation\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.append(nn.Linear(input_shape,self.width))\n",
    "        for _ in range(1,self.depth-1):\n",
    "            self.layers.append(nn.Linear(width,self.width))\n",
    "        self.layers.append(nn.Linear(self.width,1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for i in range(0,self.depth-1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr_ = 0.001\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    \"\"\"Helper function for getting the accuracy of a batch.\"\"\"\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc\n",
    "\n",
    "def train_model(model):\n",
    "    \"\"\"Train a model with the specified dimensions and activation fn.\"\"\"\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=lr_)\n",
    "    # Combines sigmoid and BCE in one class\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    model.train()\n",
    "    for e in range(1, epochs+1):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "\n",
    "            loss = loss_fn(y_pred, y_batch.unsqueeze(1))\n",
    "            acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return epoch_loss/len(train_loader), epoch_acc/len(train_loader)\n",
    "        \n",
    "def evaluate_model(model, test_loader, y_test):\n",
    "    \"\"\"Return the accuracy on a test or validation set\"\"\"\n",
    "    y_pred_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    return np.mean(y_pred_list == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 16| Depth: 2 | Activation: ReLU | Train Accuracy: 77.28368794326241 | Validation Accuracy: 0.7591921284308648\n",
      "Width: 16| Depth: 2 | Activation: tanh | Train Accuracy: 77.09219858156028 | Validation Accuracy: 0.7591921284308648\n",
      "Width: 16| Depth: 3 | Activation: ReLU | Train Accuracy: 77.0354609929078 | Validation Accuracy: 0.7607457276022787\n",
      "Width: 16| Depth: 3 | Activation: tanh | Train Accuracy: 76.95744680851064 | Validation Accuracy: 0.7622993267736924\n",
      "Width: 16| Depth: 4 | Activation: ReLU | Train Accuracy: 77.14893617021276 | Validation Accuracy: 0.7586742620403936\n",
      "Width: 16| Depth: 4 | Activation: tanh | Train Accuracy: 77.09219858156028 | Validation Accuracy: 0.7622993267736924\n",
      "Width: 32| Depth: 2 | Activation: ReLU | Train Accuracy: 77.38297872340425 | Validation Accuracy: 0.7659243915069912\n",
      "Width: 32| Depth: 2 | Activation: tanh | Train Accuracy: 76.8936170212766 | Validation Accuracy: 0.7602278612118073\n",
      "Width: 32| Depth: 3 | Activation: ReLU | Train Accuracy: 77.25531914893617 | Validation Accuracy: 0.7628171931641636\n",
      "Width: 32| Depth: 3 | Activation: tanh | Train Accuracy: 77.17021276595744 | Validation Accuracy: 0.7638529259451061\n",
      "Width: 32| Depth: 4 | Activation: ReLU | Train Accuracy: 77.34751773049645 | Validation Accuracy: 0.7591921284308648\n",
      "Width: 32| Depth: 4 | Activation: tanh | Train Accuracy: 77.09219858156028 | Validation Accuracy: 0.7612635939927499\n",
      "Width: 64| Depth: 2 | Activation: ReLU | Train Accuracy: 77.28368794326241 | Validation Accuracy: 0.7633350595546349\n",
      "Width: 64| Depth: 2 | Activation: tanh | Train Accuracy: 77.02836879432624 | Validation Accuracy: 0.7602278612118073\n",
      "Width: 64| Depth: 3 | Activation: ReLU | Train Accuracy: 77.35460992907801 | Validation Accuracy: 0.7648886587260487\n",
      "Width: 64| Depth: 3 | Activation: tanh | Train Accuracy: 77.07801418439716 | Validation Accuracy: 0.7607457276022787\n",
      "Width: 64| Depth: 4 | Activation: ReLU | Train Accuracy: 77.25531914893617 | Validation Accuracy: 0.76540652511652\n",
      "Width: 64| Depth: 4 | Activation: tanh | Train Accuracy: 77.12765957446808 | Validation Accuracy: 0.7602278612118073\n"
     ]
    }
   ],
   "source": [
    "widths = [16, 32, 64]\n",
    "depths = [2, 3, 4]\n",
    "activations = {torch.relu : 'ReLU', torch.tanh : 'tanh'}\n",
    "for width in widths:\n",
    "    for depth in depths:\n",
    "        for activation in activations.keys():\n",
    "            # Model , Optimizer, Loss\n",
    "            model = Net(input_shape=X_train.shape[1],width = width, depth = depth, activation = activation)\n",
    "            model.to(device)\n",
    "            train_loss, train_acc = train_model(model)\n",
    "            validation_acc = evaluate_model(model, validation_loader, y_val)\n",
    "            print(f'Width: {width}| Depth: {depth} | Activation: {activations[activation]} | Train Accuracy: {train_acc} | Validation Accuracy: {validation_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the validation set for training final model\n",
    "X_train = np.concatenate((X_train, X_val))\n",
    "y_train = np.concatenate((y, y_val))\n",
    "trainset = trainData(X_train,y_train)\n",
    "train_loader = DataLoader(trainset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5113394495687986, 77.44444444444444)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train best model\n",
    "width = 32\n",
    "depth = 2\n",
    "activation = torch.relu\n",
    "model = Net(input_shape=X_train.shape[1],width = width, depth = depth, activation = activation)\n",
    "model.to(device)\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.814     0.624     0.706       881\n",
      "           1      0.736     0.880     0.802      1050\n",
      "\n",
      "    accuracy                          0.763      1931\n",
      "   macro avg      0.775     0.752     0.754      1931\n",
      "weighted avg      0.772     0.763     0.758      1931\n",
      "\n",
      "[[550 331]\n",
      " [126 924]]\n",
      "Accuracy:\n",
      "0.7633350595546349\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list, digits=3))\n",
    "print(confusion_matrix(y_test,y_pred_list))\n",
    "print(\"Accuracy:\")\n",
    "print(np.mean(y_pred_list == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
